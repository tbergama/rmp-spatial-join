{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FTS Timestamp</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>WS fDOM QSU</th>\n",
       "      <th>WS fCHLA ug/L</th>\n",
       "      <th>SUNA NO3 uM</th>\n",
       "      <th>UCI Timestamp</th>\n",
       "      <th>Processed NO3(uMol)</th>\n",
       "      <th>CStar Tr</th>\n",
       "      <th>CStar c</th>\n",
       "      <th>...</th>\n",
       "      <th>EXO DO mg L</th>\n",
       "      <th>EXO DO sat</th>\n",
       "      <th>EXO Turb FNU</th>\n",
       "      <th>EXO fDOM QSU</th>\n",
       "      <th>EXO fCHLA ug/L</th>\n",
       "      <th>EXO fBGAPC ug L</th>\n",
       "      <th>index_right</th>\n",
       "      <th>Poly_ID_01</th>\n",
       "      <th>Poly_ID_5</th>\n",
       "      <th>Poly_ID_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-08-23 08:49:43</td>\n",
       "      <td>38.169900</td>\n",
       "      <td>-121.674155</td>\n",
       "      <td>21.573216</td>\n",
       "      <td>1.989287</td>\n",
       "      <td>4.755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.664697</td>\n",
       "      <td>4.084245</td>\n",
       "      <td>...</td>\n",
       "      <td>8.340</td>\n",
       "      <td>94.140</td>\n",
       "      <td>4.330</td>\n",
       "      <td>18.810668</td>\n",
       "      <td>0.260341</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1738.0</td>\n",
       "      <td>A666</td>\n",
       "      <td>C14</td>\n",
       "      <td>B67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-08-23 08:49:44</td>\n",
       "      <td>38.169890</td>\n",
       "      <td>-121.674150</td>\n",
       "      <td>21.573568</td>\n",
       "      <td>1.987489</td>\n",
       "      <td>4.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.664816</td>\n",
       "      <td>4.082456</td>\n",
       "      <td>...</td>\n",
       "      <td>8.340</td>\n",
       "      <td>94.160</td>\n",
       "      <td>4.320</td>\n",
       "      <td>18.794815</td>\n",
       "      <td>0.260341</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1738.0</td>\n",
       "      <td>A666</td>\n",
       "      <td>C14</td>\n",
       "      <td>B67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-08-23 08:49:45</td>\n",
       "      <td>38.169890</td>\n",
       "      <td>-121.674150</td>\n",
       "      <td>21.573216</td>\n",
       "      <td>1.985836</td>\n",
       "      <td>4.755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.665274</td>\n",
       "      <td>4.075569</td>\n",
       "      <td>...</td>\n",
       "      <td>8.345</td>\n",
       "      <td>94.170</td>\n",
       "      <td>4.305</td>\n",
       "      <td>18.778682</td>\n",
       "      <td>0.255520</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1738.0</td>\n",
       "      <td>A666</td>\n",
       "      <td>C14</td>\n",
       "      <td>B67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-08-23 08:49:46</td>\n",
       "      <td>38.169880</td>\n",
       "      <td>-121.674130</td>\n",
       "      <td>21.572864</td>\n",
       "      <td>1.984182</td>\n",
       "      <td>4.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.665732</td>\n",
       "      <td>4.068682</td>\n",
       "      <td>...</td>\n",
       "      <td>8.350</td>\n",
       "      <td>94.180</td>\n",
       "      <td>4.290</td>\n",
       "      <td>18.762550</td>\n",
       "      <td>0.250699</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1738.0</td>\n",
       "      <td>A666</td>\n",
       "      <td>C14</td>\n",
       "      <td>B67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-08-23 08:49:47</td>\n",
       "      <td>38.169875</td>\n",
       "      <td>-121.674120</td>\n",
       "      <td>21.566991</td>\n",
       "      <td>1.981550</td>\n",
       "      <td>4.755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.665924</td>\n",
       "      <td>4.065797</td>\n",
       "      <td>...</td>\n",
       "      <td>8.350</td>\n",
       "      <td>94.195</td>\n",
       "      <td>4.280</td>\n",
       "      <td>18.753300</td>\n",
       "      <td>0.236236</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1738.0</td>\n",
       "      <td>A666</td>\n",
       "      <td>C14</td>\n",
       "      <td>B67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         FTS Timestamp   Latitude   Longitude  WS fDOM QSU  WS fCHLA ug/L  \\\n",
       "0  2018-08-23 08:49:43  38.169900 -121.674155    21.573216       1.989287   \n",
       "1  2018-08-23 08:49:44  38.169890 -121.674150    21.573568       1.987489   \n",
       "2  2018-08-23 08:49:45  38.169890 -121.674150    21.573216       1.985836   \n",
       "3  2018-08-23 08:49:46  38.169880 -121.674130    21.572864       1.984182   \n",
       "4  2018-08-23 08:49:47  38.169875 -121.674120    21.566991       1.981550   \n",
       "\n",
       "   SUNA NO3 uM UCI Timestamp  Processed NO3(uMol)  CStar Tr   CStar c  ...  \\\n",
       "0        4.755           NaN                  NaN  0.664697  4.084245  ...   \n",
       "1        4.750           NaN                  NaN  0.664816  4.082456  ...   \n",
       "2        4.755           NaN                  NaN  0.665274  4.075569  ...   \n",
       "3        4.750           NaN                  NaN  0.665732  4.068682  ...   \n",
       "4        4.755           NaN                  NaN  0.665924  4.065797  ...   \n",
       "\n",
       "   EXO DO mg L  EXO DO sat  EXO Turb FNU  EXO fDOM QSU  EXO fCHLA ug/L  \\\n",
       "0        8.340      94.140         4.330     18.810668        0.260341   \n",
       "1        8.340      94.160         4.320     18.794815        0.260341   \n",
       "2        8.345      94.170         4.305     18.778682        0.255520   \n",
       "3        8.350      94.180         4.290     18.762550        0.250699   \n",
       "4        8.350      94.195         4.280     18.753300        0.236236   \n",
       "\n",
       "   EXO fBGAPC ug L  index_right  Poly_ID_01  Poly_ID_5  Poly_ID_1  \n",
       "0             0.11       1738.0        A666        C14        B67  \n",
       "1             0.11       1738.0        A666        C14        B67  \n",
       "2             0.11       1738.0        A666        C14        B67  \n",
       "3             0.11       1738.0        A666        C14        B67  \n",
       "4             0.11       1738.0        A666        C14        B67  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os \n",
    "import string\n",
    "os.getcwd()\n",
    "\n",
    "# Path to data file\n",
    "# Note that you may need to add an extra slash (\"\\\") in front of the existing slashes to avoid errors\n",
    "data_path = Path(\"C:\\\\Users\\\\jsoto\\\\DOI\\\\BGC Projects (v3) - Documents\\\\Mapping Data Workflow\\\\Mapping Directory for Spatial Join and Statistics\\\\Toe Pulse 2018\\\\Data\\\\Spatial Join\\\\2018-08-23_fts_20secMed_QAQC_ebs_120619_spatialJoin.csv\")\n",
    "\n",
    "df_data = pd.read_csv(data_path)\n",
    "df_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FTS Timestamp', 'Latitude', 'Longitude', 'WS fDOM QSU',\n",
       "       'WS fCHLA ug/L', 'SUNA NO3 uM', 'UCI Timestamp',\n",
       "       'Processed NO3(uMol)', 'CStar Tr', 'CStar c', 'TSG Temp',\n",
       "       'TSG Cond', 'TSG Salinity', 'EXO Temp', 'EXO Sp Cond', 'EXO pH',\n",
       "       'EXO pH mV', 'EXO DO mg L', 'EXO DO sat', 'EXO Turb FNU',\n",
       "       'EXO fDOM QSU', 'EXO fCHLA ug/L', 'EXO fBGAPC ug L', 'index_right',\n",
       "       'Poly_ID_01', 'Poly_ID_5', 'Poly_ID_1'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets see what columns we have\n",
    "df_data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26241\n",
      "25876\n"
     ]
    }
   ],
   "source": [
    "# Make a variable for the polygon id column name\n",
    "# Change this to the name you identified in the list above\n",
    "poly_id_col = \"Poly_ID_01\"\n",
    "\n",
    "# Remove nulls in \"Poly_ID column\"\n",
    "print(len(df_data))\n",
    "df_data = df_data.dropna(subset=[poly_id_01_col])\n",
    "print(len(df_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['WS fDOM QSU', 'WS fCHLA ug/L', 'SUNA NO3 uM',\n",
       "       'Processed NO3(uMol)', 'CStar Tr', 'CStar c', 'TSG Temp',\n",
       "       'TSG Cond', 'TSG Salinity', 'EXO Temp', 'EXO Sp Cond', 'EXO pH',\n",
       "       'EXO pH mV', 'EXO DO mg L', 'EXO DO sat', 'EXO Turb FNU',\n",
       "       'EXO fDOM QSU', 'EXO fCHLA ug/L', 'EXO fBGAPC ug L', 'Poly_ID_01',\n",
       "       'Poly_ID_5', 'Poly_ID_1'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now lets make a list of the ones we don't want to include\n",
    "# I am just copy/pasting non-constituent columns from above into this list\n",
    "cols_to_drop = [\n",
    "    'FTS Timestamp', 'Latitude', 'Longitude', 'index_right', 'UCI Timestamp']\n",
    "\n",
    "df_data = df_data.drop(cols_to_drop, axis=\"columns\")\n",
    "df_data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>WS fDOM QSU min</th>\n",
       "      <th>WS fDOM QSU max</th>\n",
       "      <th>WS fDOM QSU mean</th>\n",
       "      <th>WS fDOM QSU median</th>\n",
       "      <th>WS fDOM QSU std</th>\n",
       "      <th>WS fCHLA ug/L min</th>\n",
       "      <th>WS fCHLA ug/L max</th>\n",
       "      <th>WS fCHLA ug/L mean</th>\n",
       "      <th>WS fCHLA ug/L median</th>\n",
       "      <th>WS fCHLA ug/L std</th>\n",
       "      <th>...</th>\n",
       "      <th>EXO fCHLA ug/L min</th>\n",
       "      <th>EXO fCHLA ug/L max</th>\n",
       "      <th>EXO fCHLA ug/L mean</th>\n",
       "      <th>EXO fCHLA ug/L median</th>\n",
       "      <th>EXO fCHLA ug/L std</th>\n",
       "      <th>EXO fBGAPC ug L min</th>\n",
       "      <th>EXO fBGAPC ug L max</th>\n",
       "      <th>EXO fBGAPC ug L mean</th>\n",
       "      <th>EXO fBGAPC ug L median</th>\n",
       "      <th>EXO fBGAPC ug L std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Poly_ID_01</th>\n",
       "      <th>Poly_ID_1</th>\n",
       "      <th>Poly_ID_5</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1971</th>\n",
       "      <th>B196</th>\n",
       "      <th>C46</th>\n",
       "      <td>25.111473</td>\n",
       "      <td>25.486354</td>\n",
       "      <td>25.252082</td>\n",
       "      <td>25.182367</td>\n",
       "      <td>0.122197</td>\n",
       "      <td>5.203949</td>\n",
       "      <td>5.928905</td>\n",
       "      <td>5.581667</td>\n",
       "      <td>5.680690</td>\n",
       "      <td>0.238138</td>\n",
       "      <td>...</td>\n",
       "      <td>1.189956</td>\n",
       "      <td>1.562044</td>\n",
       "      <td>1.421185</td>\n",
       "      <td>1.479031</td>\n",
       "      <td>0.117109</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.267887</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.010690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1972</th>\n",
       "      <th>B196</th>\n",
       "      <th>C46</th>\n",
       "      <td>25.104558</td>\n",
       "      <td>25.436674</td>\n",
       "      <td>25.252849</td>\n",
       "      <td>25.250074</td>\n",
       "      <td>0.134483</td>\n",
       "      <td>5.155590</td>\n",
       "      <td>5.864281</td>\n",
       "      <td>5.485510</td>\n",
       "      <td>5.369775</td>\n",
       "      <td>0.311031</td>\n",
       "      <td>...</td>\n",
       "      <td>1.170699</td>\n",
       "      <td>1.474166</td>\n",
       "      <td>1.276894</td>\n",
       "      <td>1.227354</td>\n",
       "      <td>0.102381</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.252632</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.013035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1973</th>\n",
       "      <th>B196</th>\n",
       "      <th>C46</th>\n",
       "      <td>25.172762</td>\n",
       "      <td>25.327386</td>\n",
       "      <td>25.247360</td>\n",
       "      <td>25.208072</td>\n",
       "      <td>0.060869</td>\n",
       "      <td>5.135600</td>\n",
       "      <td>5.475739</td>\n",
       "      <td>5.231843</td>\n",
       "      <td>5.184100</td>\n",
       "      <td>0.103806</td>\n",
       "      <td>...</td>\n",
       "      <td>1.146522</td>\n",
       "      <td>1.245076</td>\n",
       "      <td>1.194163</td>\n",
       "      <td>1.201187</td>\n",
       "      <td>0.035197</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.242097</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.010549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1974</th>\n",
       "      <th>B196</th>\n",
       "      <th>C46</th>\n",
       "      <td>25.199575</td>\n",
       "      <td>25.373390</td>\n",
       "      <td>25.268489</td>\n",
       "      <td>25.206411</td>\n",
       "      <td>0.075131</td>\n",
       "      <td>5.023007</td>\n",
       "      <td>5.149893</td>\n",
       "      <td>5.113207</td>\n",
       "      <td>5.134629</td>\n",
       "      <td>0.038473</td>\n",
       "      <td>...</td>\n",
       "      <td>1.136805</td>\n",
       "      <td>1.191460</td>\n",
       "      <td>1.161880</td>\n",
       "      <td>1.171894</td>\n",
       "      <td>0.021620</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.239688</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>0.008418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1975</th>\n",
       "      <th>B196</th>\n",
       "      <th>C46</th>\n",
       "      <td>25.192853</td>\n",
       "      <td>25.337474</td>\n",
       "      <td>25.246212</td>\n",
       "      <td>25.240258</td>\n",
       "      <td>0.042635</td>\n",
       "      <td>4.864060</td>\n",
       "      <td>5.131899</td>\n",
       "      <td>5.003180</td>\n",
       "      <td>5.002344</td>\n",
       "      <td>0.098693</td>\n",
       "      <td>...</td>\n",
       "      <td>1.040451</td>\n",
       "      <td>1.214477</td>\n",
       "      <td>1.158403</td>\n",
       "      <td>1.166975</td>\n",
       "      <td>0.043139</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.242414</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>0.019938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                WS fDOM QSU min  WS fDOM QSU max  \\\n",
       "Poly_ID_01 Poly_ID_1 Poly_ID_5                                     \n",
       "A1971      B196      C46              25.111473        25.486354   \n",
       "A1972      B196      C46              25.104558        25.436674   \n",
       "A1973      B196      C46              25.172762        25.327386   \n",
       "A1974      B196      C46              25.199575        25.373390   \n",
       "A1975      B196      C46              25.192853        25.337474   \n",
       "\n",
       "                                WS fDOM QSU mean  WS fDOM QSU median  \\\n",
       "Poly_ID_01 Poly_ID_1 Poly_ID_5                                         \n",
       "A1971      B196      C46               25.252082           25.182367   \n",
       "A1972      B196      C46               25.252849           25.250074   \n",
       "A1973      B196      C46               25.247360           25.208072   \n",
       "A1974      B196      C46               25.268489           25.206411   \n",
       "A1975      B196      C46               25.246212           25.240258   \n",
       "\n",
       "                                WS fDOM QSU std  WS fCHLA ug/L min  \\\n",
       "Poly_ID_01 Poly_ID_1 Poly_ID_5                                       \n",
       "A1971      B196      C46               0.122197           5.203949   \n",
       "A1972      B196      C46               0.134483           5.155590   \n",
       "A1973      B196      C46               0.060869           5.135600   \n",
       "A1974      B196      C46               0.075131           5.023007   \n",
       "A1975      B196      C46               0.042635           4.864060   \n",
       "\n",
       "                                WS fCHLA ug/L max  WS fCHLA ug/L mean  \\\n",
       "Poly_ID_01 Poly_ID_1 Poly_ID_5                                          \n",
       "A1971      B196      C46                 5.928905            5.581667   \n",
       "A1972      B196      C46                 5.864281            5.485510   \n",
       "A1973      B196      C46                 5.475739            5.231843   \n",
       "A1974      B196      C46                 5.149893            5.113207   \n",
       "A1975      B196      C46                 5.131899            5.003180   \n",
       "\n",
       "                                WS fCHLA ug/L median  WS fCHLA ug/L std  ...  \\\n",
       "Poly_ID_01 Poly_ID_1 Poly_ID_5                                           ...   \n",
       "A1971      B196      C46                    5.680690           0.238138  ...   \n",
       "A1972      B196      C46                    5.369775           0.311031  ...   \n",
       "A1973      B196      C46                    5.184100           0.103806  ...   \n",
       "A1974      B196      C46                    5.134629           0.038473  ...   \n",
       "A1975      B196      C46                    5.002344           0.098693  ...   \n",
       "\n",
       "                                EXO fCHLA ug/L min  EXO fCHLA ug/L max  \\\n",
       "Poly_ID_01 Poly_ID_1 Poly_ID_5                                           \n",
       "A1971      B196      C46                  1.189956            1.562044   \n",
       "A1972      B196      C46                  1.170699            1.474166   \n",
       "A1973      B196      C46                  1.146522            1.245076   \n",
       "A1974      B196      C46                  1.136805            1.191460   \n",
       "A1975      B196      C46                  1.040451            1.214477   \n",
       "\n",
       "                                EXO fCHLA ug/L mean  EXO fCHLA ug/L median  \\\n",
       "Poly_ID_01 Poly_ID_1 Poly_ID_5                                               \n",
       "A1971      B196      C46                   1.421185               1.479031   \n",
       "A1972      B196      C46                   1.276894               1.227354   \n",
       "A1973      B196      C46                   1.194163               1.201187   \n",
       "A1974      B196      C46                   1.161880               1.171894   \n",
       "A1975      B196      C46                   1.158403               1.166975   \n",
       "\n",
       "                                EXO fCHLA ug/L std  EXO fBGAPC ug L min  \\\n",
       "Poly_ID_01 Poly_ID_1 Poly_ID_5                                            \n",
       "A1971      B196      C46                  0.117109                 0.25   \n",
       "A1972      B196      C46                  0.102381                 0.23   \n",
       "A1973      B196      C46                  0.035197                 0.23   \n",
       "A1974      B196      C46                  0.021620                 0.23   \n",
       "A1975      B196      C46                  0.043139                 0.22   \n",
       "\n",
       "                                EXO fBGAPC ug L max  EXO fBGAPC ug L mean  \\\n",
       "Poly_ID_01 Poly_ID_1 Poly_ID_5                                              \n",
       "A1971      B196      C46                      0.290              0.267887   \n",
       "A1972      B196      C46                      0.270              0.252632   \n",
       "A1973      B196      C46                      0.255              0.242097   \n",
       "A1974      B196      C46                      0.250              0.239688   \n",
       "A1975      B196      C46                      0.270              0.242414   \n",
       "\n",
       "                                EXO fBGAPC ug L median  EXO fBGAPC ug L std  \n",
       "Poly_ID_01 Poly_ID_1 Poly_ID_5                                               \n",
       "A1971      B196      C46                        0.2700             0.010690  \n",
       "A1972      B196      C46                        0.2575             0.013035  \n",
       "A1973      B196      C46                        0.2500             0.010549  \n",
       "A1974      B196      C46                        0.2400             0.008418  \n",
       "A1975      B196      C46                        0.2300             0.019938  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute Stats\n",
    "# First group the data by poly_id_col\n",
    "df_grouped = df_data.groupby([\"Poly_ID_01\", \"Poly_ID_1\", \"Poly_ID_5\"])\n",
    "\n",
    "# Now lets define the statistics we want to compute in a list that we can pass to the pandas aggregation function\n",
    "# For more information on what can go into this list check out: \n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.agg.html\n",
    "#KO: added std to stats list 5/19/2020\n",
    "\n",
    "stats = [\n",
    "    \"min\",\n",
    "    \"max\",\n",
    "    \"mean\",\n",
    "    \"median\",\n",
    "    \"std\"\n",
    "]\n",
    "\n",
    "# Compute the statistics defined above for each polygon\n",
    "df_stats = df_grouped.agg(stats)\n",
    "\n",
    "# Flatten the hierarchical columns\n",
    "df_stats.columns = [' '.join(col).strip() for col in df_stats.columns.values]\n",
    "\n",
    "df_stats.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jsoto\\Anaconda3\\envs\\rmp-spatial-join-stats\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of standard deviations converging on:  813454.7279051931\n",
      "Sum of standard deviations converging on:  718223.9279707769\n",
      "Sum of standard deviations converging on:  690186.3337507612\n",
      "Sum of standard deviations converging on:  675974.2723238434\n",
      "Sum of standard deviations converging on:  669820.0963102308\n",
      "Sum of standard deviations converging on:  666024.8616835749\n",
      "Sum of standard deviations converging on:  663910.9134446593\n",
      "Sum of standard deviations converging on:  662695.4852388576\n",
      "Sum of standard deviations converging on:  661746.6936432264\n",
      "Sum of standard deviations converging on:  660733.7693987049\n",
      "Sum of standard deviations converging on:  660244.0472059425\n",
      "Sum of standard deviations converging on:  660061.8552914241\n"
     ]
    }
   ],
   "source": [
    "# run the loop desired number of times. final output file will have the stats based on the final loop. \n",
    "# adjust number of iterations to make sure values converge using printed stat below\n",
    "num_iterations = 12\n",
    "tmp_df_data = df_data.copy() #copy of original df_data to preserve data\n",
    "tmp_df_stats = df_stats.copy() \n",
    "for num in range(num_iterations):\n",
    "    \n",
    "    # merge original data and stats dataframes on poly ID\n",
    "    df_merged = df_data.merge(tmp_df_stats, how = 'outer', left_on = 'Poly_ID_01', right_on = 'Poly_ID_01')\n",
    "    \n",
    "    convergence = 0\n",
    "    for col in df_data.columns:\n",
    "        # skip location, poly_id, lat, long columns when filtering data\n",
    "        if col in ('FTS Timestamp', 'Latitude', 'Longitude', 'index_right', 'UCI Timestamp', 'Poly_ID_01', 'Poly_ID_1', 'Poly_ID_5'):\n",
    "            continue\n",
    " \n",
    "        # creates series to hold mean and standard deviation values\n",
    "        col_mean = col + ' mean' \n",
    "        col_std = col + ' std' # standard deviation\n",
    "\n",
    "        # calculates and creates a column for 2x std\n",
    "        col_2xstd = 2*df_merged[col_std]\n",
    "\n",
    "        # calculates the difference between the instantaneous value and the mean value of its corresponding polygon\n",
    "        col_diff_mean = abs(df_merged[col] - df_merged[col_mean])\n",
    "\n",
    "        # if the difference between the instantenous value and the mean is greater than 2xstd replace the value with a NAN\n",
    "        remove_mask = col_diff_mean > col_2xstd\n",
    "        df_merged[col][remove_mask] = np.nan   \n",
    "        convergence += col_2xstd.sum()\n",
    "    print(\"Sum of standard deviations converging on: \", convergence)\n",
    "\n",
    "    # creates dataframe, df_data_filtered\n",
    "    # dropping extra columns created during filtering\n",
    "    # filtered data retained, and columns kept are based on columns that existed in df_data\n",
    "    tmp_df_data = df_merged[df_data.columns]\n",
    "    \n",
    "    # Re-run stats on filtered data\n",
    "    df_grouped_filtered = tmp_df_data.groupby([\"Poly_ID_01\", \"Poly_ID_1\", \"Poly_ID_5\"])\n",
    "\n",
    "    # Compute the statistics defined above for each polygon\n",
    "    tmp_df_stats = df_grouped_filtered.agg(stats)\n",
    "    \n",
    "    # Flatten the hierarchical columns\n",
    "    tmp_df_stats.columns = [' '.join(col).strip() for col in tmp_df_stats.columns.values]\n",
    "\n",
    "# change name of dataframe for clarity after processing\n",
    "df_stats_filtered = tmp_df_stats\n",
    "\n",
    "tmp_df_stats\n",
    "\n",
    "# stats for each polygon based on final iteration of above loop\n",
    "# Write output file\n",
    "out_dir = \"C:\\\\Users\\\\jsoto\\\\DOI\\\\BGC Projects (v3) - Documents\\\\Mapping Data Workflow\\\\Mapping Directory for Spatial Join and Statistics\\\\Toe Pulse 2018\\\\Data\\\\Statistics\"\n",
    "out_fname = data_path.name.split(\".\")[0] + \"_statsTest.csv\"\n",
    "out_path = Path(out_dir, out_fname)\n",
    "\n",
    "# Flatten the hierarchical columns\n",
    "df_stats_filtered.columns = [''.join(col).strip() for col in df_stats_filtered.columns.values]\n",
    "\n",
    "\n",
    "# Write the csv\n",
    "df_stats_filtered.to_csv(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use a left join to append lat, long values of delta polygon center points\n",
    "# Path to center point file\n",
    "# Note that you may need to add an extra slash (\"\\\") in front of the existing slashes to avoid errors\n",
    "data_point01_path = Path(\"C:\\\\Users\\\\jsoto\\\\DOI\\\\BGC Projects (v3) - Documents\\\\Mapping Data Workflow\\\\Mapping Directory for Spatial Join and Statistics\\\\Center Points xlsx\\\\DeltaCenterPoints_01.xlsx\")\n",
    "data_point1_path = Path(\"C:\\\\Users\\\\jsoto\\\\DOI\\\\BGC Projects (v3) - Documents\\\\Mapping Data Workflow\\\\Mapping Directory for Spatial Join and Statistics\\\\Center Points xlsx\\\\DeltaCenterPoints_1.xlsx\")\n",
    "data_point5_path = Path(\"C:\\\\Users\\\\jsoto\\\\DOI\\\\BGC Projects (v3) - Documents\\\\Mapping Data Workflow\\\\Mapping Directory for Spatial Join and Statistics\\\\Center Points xlsx\\\\DeltaCenterPoints_5.xlsx\")\n",
    "\n",
    "df_point01 = pd.read_excel(data_point01_path)\n",
    "df_point1 = pd.read_excel(data_point1_path)\n",
    "df_point5 = pd.read_excel(data_point5_path)\n",
    "\n",
    "df_join01 = pd.merge(left=df_stats_filtered, right=df_point01, how='left', left_on='Poly_ID_01', right_on='CL_ID')\n",
    "df_join1 = pd.merge(left=df_stats_filtered, right=df_point1, how='left', left_on='Poly_ID_1', right_on='CL_ID')\n",
    "df_join5 = pd.merge(left=df_stats_filtered, right=df_point5, how='left', left_on='Poly_ID_5', right_on='CL_ID')\n",
    "\n",
    "# stats for each polygon based on final iteration of above loop joined with CL_ID\n",
    "# Write output file\n",
    "out_dir2 = \"C:\\\\Users\\\\jsoto\\\\DOI\\\\BGC Projects (v3) - Documents\\\\Mapping Data Workflow\\Mapping Directory for Spatial Join and Statistics\\\\Toe Pulse 2018\\\\Data\\\\CL_ID Join\"\n",
    "out_fname01 = data_path.name.split(\".\")[0] + \"_statsTest_join01.csv\"\n",
    "out_path01 = Path(out_dir2, out_fname01)\n",
    "\n",
    "out_fname1 = data_path.name.split(\".\")[0] + \"_statsTest_join1.csv\"\n",
    "out_path1 = Path(out_dir2, out_fname1)\n",
    "\n",
    "out_fname5 = data_path.name.split(\".\")[0] + \"_statsTest_join5.csv\"\n",
    "out_path5 = Path(out_dir2, out_fname5)\n",
    "\n",
    "# Flatten the hierarchical columns\n",
    "df_join01.columns = [''.join(col).strip() for col in df_join01.columns.values]\n",
    "df_join1.columns = [''.join(col).strip() for col in df_join1.columns.values]\n",
    "df_join5.columns = [''.join(col).strip() for col in df_join5.columns.values]\n",
    "\n",
    "# Write the csv\n",
    "df_join01.to_csv(out_path01)\n",
    "df_join1.to_csv(out_path1)\n",
    "df_join5.to_csv(out_path5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
