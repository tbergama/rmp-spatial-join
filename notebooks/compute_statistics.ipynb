{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read the file produced by `assign_polys.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tbergamaschi\\Anaconda3\\envs\\iwaas\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3062: DtypeWarning: Columns (101) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FTS Timestamp</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>WS fDOM QSU</th>\n",
       "      <th>WS fCHLA ug/L</th>\n",
       "      <th>NO3 uM</th>\n",
       "      <th>CStar Tr</th>\n",
       "      <th>CStar c</th>\n",
       "      <th>TSG Temp</th>\n",
       "      <th>TSG Cond</th>\n",
       "      <th>...</th>\n",
       "      <th>Discrete PICO \\nPE-RICH</th>\n",
       "      <th>Discrete Pico DENSITY (cells/L)</th>\n",
       "      <th>Discrete PICO\\nPC-RICH</th>\n",
       "      <th>Discrete Pico DENSITY (cells/L) .1</th>\n",
       "      <th>Discrete Pico TOTAL</th>\n",
       "      <th>Discrete Pico Notes from BSA</th>\n",
       "      <th>index_right</th>\n",
       "      <th>CL_ID</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>Shape_Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>05/15/2018 07:40:01</td>\n",
       "      <td>38.571040</td>\n",
       "      <td>-121.516280</td>\n",
       "      <td>16.460</td>\n",
       "      <td>6.912</td>\n",
       "      <td>2.919</td>\n",
       "      <td>0.595</td>\n",
       "      <td>5.187</td>\n",
       "      <td>18.914</td>\n",
       "      <td>118.65</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05/15/2018 07:40:02</td>\n",
       "      <td>38.571040</td>\n",
       "      <td>-121.516280</td>\n",
       "      <td>16.463</td>\n",
       "      <td>6.973</td>\n",
       "      <td>2.941</td>\n",
       "      <td>0.595</td>\n",
       "      <td>5.190</td>\n",
       "      <td>18.912</td>\n",
       "      <td>118.60</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05/15/2018 07:40:03</td>\n",
       "      <td>38.571035</td>\n",
       "      <td>-121.516300</td>\n",
       "      <td>16.469</td>\n",
       "      <td>7.037</td>\n",
       "      <td>2.963</td>\n",
       "      <td>0.595</td>\n",
       "      <td>5.195</td>\n",
       "      <td>18.910</td>\n",
       "      <td>118.55</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05/15/2018 07:40:04</td>\n",
       "      <td>38.571030</td>\n",
       "      <td>-121.516320</td>\n",
       "      <td>16.476</td>\n",
       "      <td>7.100</td>\n",
       "      <td>2.941</td>\n",
       "      <td>0.595</td>\n",
       "      <td>5.200</td>\n",
       "      <td>18.907</td>\n",
       "      <td>118.50</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05/15/2018 07:40:05</td>\n",
       "      <td>38.571020</td>\n",
       "      <td>-121.516325</td>\n",
       "      <td>16.482</td>\n",
       "      <td>7.091</td>\n",
       "      <td>2.919</td>\n",
       "      <td>0.595</td>\n",
       "      <td>5.200</td>\n",
       "      <td>18.906</td>\n",
       "      <td>118.50</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         FTS Timestamp   Latitude   Longitude  WS fDOM QSU  WS fCHLA ug/L  \\\n",
       "0  05/15/2018 07:40:01  38.571040 -121.516280       16.460          6.912   \n",
       "1  05/15/2018 07:40:02  38.571040 -121.516280       16.463          6.973   \n",
       "2  05/15/2018 07:40:03  38.571035 -121.516300       16.469          7.037   \n",
       "3  05/15/2018 07:40:04  38.571030 -121.516320       16.476          7.100   \n",
       "4  05/15/2018 07:40:05  38.571020 -121.516325       16.482          7.091   \n",
       "\n",
       "   NO3 uM  CStar Tr  CStar c  TSG Temp  TSG Cond  ...  \\\n",
       "0   2.919     0.595    5.187    18.914    118.65  ...   \n",
       "1   2.941     0.595    5.190    18.912    118.60  ...   \n",
       "2   2.963     0.595    5.195    18.910    118.55  ...   \n",
       "3   2.941     0.595    5.200    18.907    118.50  ...   \n",
       "4   2.919     0.595    5.200    18.906    118.50  ...   \n",
       "\n",
       "   Discrete PICO \\nPE-RICH  Discrete Pico DENSITY (cells/L)   \\\n",
       "0                      NaN                               NaN   \n",
       "1                      NaN                               NaN   \n",
       "2                      NaN                               NaN   \n",
       "3                      NaN                               NaN   \n",
       "4                      NaN                               NaN   \n",
       "\n",
       "   Discrete PICO\\nPC-RICH  Discrete Pico DENSITY (cells/L) .1  \\\n",
       "0                     NaN                                 NaN   \n",
       "1                     NaN                                 NaN   \n",
       "2                     NaN                                 NaN   \n",
       "3                     NaN                                 NaN   \n",
       "4                     NaN                                 NaN   \n",
       "\n",
       "   Discrete Pico TOTAL  Discrete Pico Notes from BSA  index_right  CL_ID  \\\n",
       "0                  NaN                           NaN          NaN    NaN   \n",
       "1                  NaN                           NaN          NaN    NaN   \n",
       "2                  NaN                           NaN          NaN    NaN   \n",
       "3                  NaN                           NaN          NaN    NaN   \n",
       "4                  NaN                           NaN          NaN    NaN   \n",
       "\n",
       "   Shape_Leng  Shape_Area  \n",
       "0         NaN         NaN  \n",
       "1         NaN         NaN  \n",
       "2         NaN         NaN  \n",
       "3         NaN         NaN  \n",
       "4         NaN         NaN  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to data file\n",
    "# Note that you may need to add an extra slash (\"\\\") in front of the existing slashes to avoid errors\n",
    "data_path = Path(\"C:\\\\Users\\\\tbergamaschi\\\\Projects\\\\rmp-spatial-join\\\\May_RMP_merged_20secMed (1)SpatialJoin.csv\")\n",
    "\n",
    "df_data = pd.read_csv(data_path)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. A little bit of clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't make sense to compute statistics for some columns in the dataset (like latitude and longitude), so lets identify the columns we don't want to include and drop them from the dataframe.\n",
    "\n",
    "*Note: we could do this the other way - by identifying the columns we want to keep - but it is my hope that the columns we want to drop will be more or less consistant from dataset to dataset, more so than the constituent columns. So hopefully identifying the columns to drop will mean that little or no modification is needed from dataset to dataset. We will see...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FTS Timestamp', 'Latitude', 'Longitude', 'WS fDOM QSU',\n",
       "       'WS fCHLA ug/L', 'NO3 uM', 'CStar Tr', 'CStar c', 'TSG Temp',\n",
       "       'TSG Cond', 'TSG Salinity', 'EXO Temp', 'EXO Sp Cond', 'EXO pH',\n",
       "       'EXO pH mV', 'EXO DO mg L', 'EXO DO sat', 'EXO Turb FNU',\n",
       "       'EXO fDOM QSU', 'EXO fCHLA ug/L', 'EXO fBGAPC ug L',\n",
       "       'Tline NH4 (uM)', 'FP Green Algae ug/L', 'FP Bluegreen ug/L',\n",
       "       'FP Diatoms ug/L', 'FP Cryptophyta ug/L', 'FP Yellow substances',\n",
       "       'FP Total conc. ug/L', 'FP Green Algae %', 'FP Bluegreen %',\n",
       "       'FP Diatoms %', 'FP Cryptophyta %', 'FP Total conc. ug/L.1',\n",
       "       'FP Transmission %', 'FP Temp. Sample deg. C', 'Discrete grNum',\n",
       "       'Discrete Station', 'Discrete Station ID', 'Discrete Latitude',\n",
       "       'Discrete Longitude', 'Discrete Date', 'Discrete Time',\n",
       "       'Discrete Timestamp', 'Discrete Datum', 'Discrete TDN (mg-N/L)',\n",
       "       'Discrete TDN (uM)', 'Discrete NH4 (mg-N/L)', 'Discrete NH4 (uM)',\n",
       "       'Discrete NO2 (mg-N/L)', 'Discrete NO2 (uM)',\n",
       "       'Discrete NO2+NO3 (mg-N/L)', 'Discrete NO2+NO3 (uM)',\n",
       "       'Discrete Ortho-PO4 (mg-P/L)', 'Discrete Ortho-PO4 (uM)',\n",
       "       'Discrete Chl-a (ug/L)', 'Discrete Pheyo. (ug/L)',\n",
       "       'Discrete Total Chl (ug/L)', 'Discrete Chl-a 5um (ug/L)',\n",
       "       'Discrete Pheyo. 5um (ug/L)', 'Discrete Phyco cyanin (Âµg/L)',\n",
       "       'Discrete Allophyco cyanin (Âµg/L)',\n",
       "       'Discrete Phyco erythrin (Âµg/L)', 'Discrete DOC (mg/L)',\n",
       "       'Discrete TDN (mg/L)', 'Discrete A 254', 'Discrete A 280',\n",
       "       'Discrete A 350', 'Discrete A 370', 'Discrete A 412',\n",
       "       'Discrete A 440', 'Discrete A 488', 'Discrete A 510',\n",
       "       'Discrete A 532', 'Discrete A 555', ' Discrete S ag 275 290',\n",
       "       ' Discrete r 275 295', ' Discrete S ag 290 350',\n",
       "       ' Discrete r 290 350', 'Discrete S ag 350 400',\n",
       "       ' Discrete r 350 400', 'Discrete S ag 412 600',\n",
       "       ' Discrete r 412 600', ' Discrete UV Slope Ratio',\n",
       "       'Discrete  A  ex 260 em 450', 'Discrete  C ex 340 em 440',\n",
       "       'Discrete  M ex 300 em 390', 'Discrete  D ex 390 em 510',\n",
       "       'Discrete  B ex 275 em 304', 'Discrete  T ex 275 em 340',\n",
       "       'Discrete  N ex 280 em 370', 'Discrete  fDOM ex 370 em 460',\n",
       "       'Discrete  BDJF ex 420 em 460', 'Discrete  FI 2005',\n",
       "       'Discrete  HI Ohno 2008', 'Discrete Pico SAMPLE\\nALIQUOT (mL)',\n",
       "       'Discrete Pico FIELDS', 'Discrete PICO \\nPE-RICH',\n",
       "       'Discrete Pico DENSITY (cells/L) ', 'Discrete PICO\\nPC-RICH',\n",
       "       'Discrete Pico DENSITY (cells/L) .1', 'Discrete Pico TOTAL',\n",
       "       'Discrete Pico Notes from BSA', 'index_right', 'CL_ID',\n",
       "       'Shape_Leng', 'Shape_Area'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First lets see what columns we have\n",
    "df_data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets make a list of the ones we don't want to include\n",
    "# I am just copy/pasting non-constituent columns from above into this list\n",
    "cols_to_drop = [\n",
    "    'FTS Timestamp', \n",
    "    'Latitude', \n",
    "    'Longitude',\n",
    "    'Discrete grNum',\n",
    "       'Discrete Station', 'Discrete Station ID', 'Discrete Latitude',\n",
    "       'Discrete Longitude', 'Discrete Date', 'Discrete Time',\n",
    "       'Discrete Timestamp', 'Discrete Datum', 'Discrete TDN (mg-N/L)',\n",
    "       'Discrete TDN (uM)', 'Discrete NH4 (mg-N/L)', 'Discrete NH4 (uM)',\n",
    "       'Discrete NO2 (mg-N/L)', 'Discrete NO2 (uM)',\n",
    "       'Discrete NO2+NO3 (mg-N/L)', 'Discrete NO2+NO3 (uM)',\n",
    "       'Discrete Ortho-PO4 (mg-P/L)', 'Discrete Ortho-PO4 (uM)',\n",
    "       'Discrete Chl-a (ug/L)', 'Discrete Pheyo. (ug/L)',\n",
    "       'Discrete Total Chl (ug/L)', 'Discrete Chl-a 5um (ug/L)',\n",
    "       'Discrete Pheyo. 5um (ug/L)', 'Discrete Phyco cyanin (Âµg/L)',\n",
    "       'Discrete Allophyco cyanin (Âµg/L)',\n",
    "       'Discrete Phyco erythrin (Âµg/L)', 'Discrete DOC (mg/L)',\n",
    "       'Discrete TDN (mg/L)', 'Discrete A 254', 'Discrete A 280',\n",
    "       'Discrete A 350', 'Discrete A 370', 'Discrete A 412',\n",
    "       'Discrete A 440', 'Discrete A 488', 'Discrete A 510',\n",
    "       'Discrete A 532', 'Discrete A 555', ' Discrete S ag 275 290',\n",
    "       ' Discrete r 275 295', ' Discrete S ag 290 350',\n",
    "       ' Discrete r 290 350', 'Discrete S ag 350 400',\n",
    "       ' Discrete r 350 400', 'Discrete S ag 412 600',\n",
    "       ' Discrete r 412 600', ' Discrete UV Slope Ratio',\n",
    "       'Discrete  A  ex 260 em 450', 'Discrete  C ex 340 em 440',\n",
    "       'Discrete  M ex 300 em 390', 'Discrete  D ex 390 em 510',\n",
    "       'Discrete  B ex 275 em 304', 'Discrete  T ex 275 em 340',\n",
    "       'Discrete  N ex 280 em 370', 'Discrete  fDOM ex 370 em 460',\n",
    "       'Discrete  BDJF ex 420 em 460', 'Discrete  FI 2005',\n",
    "       'Discrete  HI Ohno 2008', 'Discrete Pico SAMPLE\\nALIQUOT (mL)',\n",
    "       'Discrete Pico FIELDS', 'Discrete PICO \\nPE-RICH',\n",
    "       'Discrete Pico DENSITY (cells/L) ', 'Discrete PICO\\nPC-RICH',\n",
    "       'Discrete Pico DENSITY (cells/L) .1', 'Discrete Pico TOTAL',\n",
    "       'Discrete Pico Notes from BSA', 'index_right',\n",
    "    'Shape_Leng', 'Shape_Area'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['WS fDOM QSU', 'WS fCHLA ug/L', 'NO3 uM', 'CStar Tr', 'CStar c',\n",
       "       'TSG Temp', 'TSG Cond', 'TSG Salinity', 'EXO Temp', 'EXO Sp Cond',\n",
       "       'EXO pH', 'EXO pH mV', 'EXO DO mg L', 'EXO DO sat', 'EXO Turb FNU',\n",
       "       'EXO fDOM QSU', 'EXO fCHLA ug/L', 'EXO fBGAPC ug L',\n",
       "       'Tline NH4 (uM)', 'FP Green Algae ug/L', 'FP Bluegreen ug/L',\n",
       "       'FP Diatoms ug/L', 'FP Cryptophyta ug/L', 'FP Yellow substances',\n",
       "       'FP Total conc. ug/L', 'FP Green Algae %', 'FP Bluegreen %',\n",
       "       'FP Diatoms %', 'FP Cryptophyta %', 'FP Total conc. ug/L.1',\n",
       "       'FP Transmission %', 'FP Temp. Sample deg. C', 'CL_ID'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = df_data.drop(cols_to_drop, axis=\"columns\")\n",
    "df_data.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool now we just have columns that we are going to use in our statistics computation. Now we need to identify the column that contains the polygon id that was assigned by `assign_polys.py`.\n",
    "\n",
    "In this case, the column is **`'CL_ID'`**\n",
    "\n",
    "But keep in mind that this could be different in a different dataset. Look for something that looks like it means \"centerline id\" or \"polygon id\".\n",
    "\n",
    "We can't do anything with rows that do not have a polygon id, so the next step will be to drop any rows with a missing polygon id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96219\n",
      "7158\n"
     ]
    }
   ],
   "source": [
    "# Make a variable for the polygon id column name\n",
    "# Change this to the name you identified in the list above\n",
    "poly_id_col = \"CL_ID\"\n",
    "\n",
    "print(len(df_data))\n",
    "df_data = df_data.dropna(subset=[poly_id_col])\n",
    "print(len(df_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the length updated if there were any rows missing a polygon id. Now we are ready to compute statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First group the data by poly_id_col\n",
    "df_grouped = df_data.groupby(poly_id_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets define the statistics we want to compute in a list that we can pass to the pandas aggregation function\n",
    "# For more information on what can go into this list check out: \n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.agg.html\n",
    "stats = [\n",
    "    \"min\",\n",
    "    \"max\",\n",
    "    \"mean\",\n",
    "    \"median\"\n",
    "]\n",
    "\n",
    "# Compute the statistics defined above for each polygon\n",
    "df_stats = df_grouped.agg(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">WS fDOM QSU</th>\n",
       "      <th colspan=\"4\" halign=\"left\">WS fCHLA ug/L</th>\n",
       "      <th colspan=\"2\" halign=\"left\">NO3 uM</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">FP Total conc. ug/L.1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">FP Transmission %</th>\n",
       "      <th colspan=\"4\" halign=\"left\">FP Temp. Sample deg. C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>...</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202.0</th>\n",
       "      <td>21.688000</td>\n",
       "      <td>29.430</td>\n",
       "      <td>24.453300</td>\n",
       "      <td>22.288500</td>\n",
       "      <td>2.574</td>\n",
       "      <td>3.763000</td>\n",
       "      <td>3.341133</td>\n",
       "      <td>3.64800</td>\n",
       "      <td>13.306</td>\n",
       "      <td>13.743</td>\n",
       "      <td>...</td>\n",
       "      <td>3.729267</td>\n",
       "      <td>4.2390</td>\n",
       "      <td>94.855</td>\n",
       "      <td>98.785</td>\n",
       "      <td>97.617167</td>\n",
       "      <td>98.7050</td>\n",
       "      <td>18.750</td>\n",
       "      <td>19.960</td>\n",
       "      <td>19.590800</td>\n",
       "      <td>19.9400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203.0</th>\n",
       "      <td>29.447000</td>\n",
       "      <td>29.492</td>\n",
       "      <td>29.479818</td>\n",
       "      <td>29.492000</td>\n",
       "      <td>2.574</td>\n",
       "      <td>2.577000</td>\n",
       "      <td>2.575455</td>\n",
       "      <td>2.57600</td>\n",
       "      <td>13.306</td>\n",
       "      <td>13.448</td>\n",
       "      <td>...</td>\n",
       "      <td>2.489091</td>\n",
       "      <td>2.4900</td>\n",
       "      <td>95.335</td>\n",
       "      <td>95.635</td>\n",
       "      <td>95.506909</td>\n",
       "      <td>95.5100</td>\n",
       "      <td>18.770</td>\n",
       "      <td>18.790</td>\n",
       "      <td>18.779636</td>\n",
       "      <td>18.7800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204.0</th>\n",
       "      <td>28.238263</td>\n",
       "      <td>29.492</td>\n",
       "      <td>29.039260</td>\n",
       "      <td>29.466000</td>\n",
       "      <td>2.566</td>\n",
       "      <td>2.745883</td>\n",
       "      <td>2.645867</td>\n",
       "      <td>2.57500</td>\n",
       "      <td>13.301</td>\n",
       "      <td>15.388</td>\n",
       "      <td>...</td>\n",
       "      <td>2.410286</td>\n",
       "      <td>2.4670</td>\n",
       "      <td>93.155</td>\n",
       "      <td>96.070</td>\n",
       "      <td>94.756000</td>\n",
       "      <td>95.7500</td>\n",
       "      <td>18.590</td>\n",
       "      <td>18.800</td>\n",
       "      <td>18.711905</td>\n",
       "      <td>18.7900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205.0</th>\n",
       "      <td>27.987686</td>\n",
       "      <td>29.462</td>\n",
       "      <td>28.833307</td>\n",
       "      <td>29.443000</td>\n",
       "      <td>2.521</td>\n",
       "      <td>2.738661</td>\n",
       "      <td>2.631727</td>\n",
       "      <td>2.56300</td>\n",
       "      <td>13.275</td>\n",
       "      <td>15.472</td>\n",
       "      <td>...</td>\n",
       "      <td>2.422750</td>\n",
       "      <td>2.5325</td>\n",
       "      <td>93.475</td>\n",
       "      <td>96.210</td>\n",
       "      <td>95.098958</td>\n",
       "      <td>96.1050</td>\n",
       "      <td>18.600</td>\n",
       "      <td>18.800</td>\n",
       "      <td>18.714583</td>\n",
       "      <td>18.7900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206.0</th>\n",
       "      <td>27.844259</td>\n",
       "      <td>29.431</td>\n",
       "      <td>28.632156</td>\n",
       "      <td>28.649771</td>\n",
       "      <td>2.485</td>\n",
       "      <td>2.765952</td>\n",
       "      <td>2.618024</td>\n",
       "      <td>2.62091</td>\n",
       "      <td>13.751</td>\n",
       "      <td>15.867</td>\n",
       "      <td>...</td>\n",
       "      <td>2.387318</td>\n",
       "      <td>2.3710</td>\n",
       "      <td>94.140</td>\n",
       "      <td>96.145</td>\n",
       "      <td>95.072818</td>\n",
       "      <td>95.0250</td>\n",
       "      <td>18.630</td>\n",
       "      <td>18.790</td>\n",
       "      <td>18.718455</td>\n",
       "      <td>18.7275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524.0</th>\n",
       "      <td>41.930000</td>\n",
       "      <td>42.321</td>\n",
       "      <td>42.127083</td>\n",
       "      <td>42.131500</td>\n",
       "      <td>2.766</td>\n",
       "      <td>2.774000</td>\n",
       "      <td>2.770917</td>\n",
       "      <td>2.77100</td>\n",
       "      <td>3.231</td>\n",
       "      <td>3.279</td>\n",
       "      <td>...</td>\n",
       "      <td>1.916917</td>\n",
       "      <td>1.9150</td>\n",
       "      <td>76.340</td>\n",
       "      <td>76.660</td>\n",
       "      <td>76.555000</td>\n",
       "      <td>76.5850</td>\n",
       "      <td>19.235</td>\n",
       "      <td>19.320</td>\n",
       "      <td>19.275417</td>\n",
       "      <td>19.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525.0</th>\n",
       "      <td>41.744000</td>\n",
       "      <td>41.906</td>\n",
       "      <td>41.852083</td>\n",
       "      <td>41.851500</td>\n",
       "      <td>2.771</td>\n",
       "      <td>2.807000</td>\n",
       "      <td>2.785500</td>\n",
       "      <td>2.78300</td>\n",
       "      <td>3.001</td>\n",
       "      <td>3.244</td>\n",
       "      <td>...</td>\n",
       "      <td>1.896333</td>\n",
       "      <td>1.8925</td>\n",
       "      <td>76.605</td>\n",
       "      <td>76.725</td>\n",
       "      <td>76.699583</td>\n",
       "      <td>76.7250</td>\n",
       "      <td>19.150</td>\n",
       "      <td>19.225</td>\n",
       "      <td>19.194167</td>\n",
       "      <td>19.2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526.0</th>\n",
       "      <td>41.186000</td>\n",
       "      <td>41.690</td>\n",
       "      <td>41.452250</td>\n",
       "      <td>41.428000</td>\n",
       "      <td>2.808</td>\n",
       "      <td>2.826000</td>\n",
       "      <td>2.815583</td>\n",
       "      <td>2.81700</td>\n",
       "      <td>2.885</td>\n",
       "      <td>3.057</td>\n",
       "      <td>...</td>\n",
       "      <td>1.921667</td>\n",
       "      <td>1.9275</td>\n",
       "      <td>75.975</td>\n",
       "      <td>76.570</td>\n",
       "      <td>76.360083</td>\n",
       "      <td>76.4100</td>\n",
       "      <td>19.065</td>\n",
       "      <td>19.143</td>\n",
       "      <td>19.098333</td>\n",
       "      <td>19.0975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527.0</th>\n",
       "      <td>40.743000</td>\n",
       "      <td>41.177</td>\n",
       "      <td>41.008727</td>\n",
       "      <td>41.057000</td>\n",
       "      <td>2.736</td>\n",
       "      <td>2.817000</td>\n",
       "      <td>2.758364</td>\n",
       "      <td>2.74500</td>\n",
       "      <td>2.787</td>\n",
       "      <td>2.886</td>\n",
       "      <td>...</td>\n",
       "      <td>1.947727</td>\n",
       "      <td>1.9450</td>\n",
       "      <td>75.290</td>\n",
       "      <td>75.765</td>\n",
       "      <td>75.410909</td>\n",
       "      <td>75.2900</td>\n",
       "      <td>19.000</td>\n",
       "      <td>19.060</td>\n",
       "      <td>19.021818</td>\n",
       "      <td>19.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528.0</th>\n",
       "      <td>40.264000</td>\n",
       "      <td>40.632</td>\n",
       "      <td>40.450000</td>\n",
       "      <td>40.459500</td>\n",
       "      <td>2.732</td>\n",
       "      <td>2.737000</td>\n",
       "      <td>2.735667</td>\n",
       "      <td>2.73600</td>\n",
       "      <td>2.818</td>\n",
       "      <td>2.880</td>\n",
       "      <td>...</td>\n",
       "      <td>1.930917</td>\n",
       "      <td>1.9230</td>\n",
       "      <td>75.290</td>\n",
       "      <td>76.145</td>\n",
       "      <td>75.695417</td>\n",
       "      <td>75.6875</td>\n",
       "      <td>18.950</td>\n",
       "      <td>18.990</td>\n",
       "      <td>18.965417</td>\n",
       "      <td>18.9675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>237 rows Ã— 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      WS fDOM QSU                               WS fCHLA ug/L            \\\n",
       "              min     max       mean     median           min       max   \n",
       "CL_ID                                                                     \n",
       "202.0   21.688000  29.430  24.453300  22.288500         2.574  3.763000   \n",
       "203.0   29.447000  29.492  29.479818  29.492000         2.574  2.577000   \n",
       "204.0   28.238263  29.492  29.039260  29.466000         2.566  2.745883   \n",
       "205.0   27.987686  29.462  28.833307  29.443000         2.521  2.738661   \n",
       "206.0   27.844259  29.431  28.632156  28.649771         2.485  2.765952   \n",
       "...           ...     ...        ...        ...           ...       ...   \n",
       "524.0   41.930000  42.321  42.127083  42.131500         2.766  2.774000   \n",
       "525.0   41.744000  41.906  41.852083  41.851500         2.771  2.807000   \n",
       "526.0   41.186000  41.690  41.452250  41.428000         2.808  2.826000   \n",
       "527.0   40.743000  41.177  41.008727  41.057000         2.736  2.817000   \n",
       "528.0   40.264000  40.632  40.450000  40.459500         2.732  2.737000   \n",
       "\n",
       "                          NO3 uM          ... FP Total conc. ug/L.1          \\\n",
       "           mean   median     min     max  ...                  mean  median   \n",
       "CL_ID                                     ...                                 \n",
       "202.0  3.341133  3.64800  13.306  13.743  ...              3.729267  4.2390   \n",
       "203.0  2.575455  2.57600  13.306  13.448  ...              2.489091  2.4900   \n",
       "204.0  2.645867  2.57500  13.301  15.388  ...              2.410286  2.4670   \n",
       "205.0  2.631727  2.56300  13.275  15.472  ...              2.422750  2.5325   \n",
       "206.0  2.618024  2.62091  13.751  15.867  ...              2.387318  2.3710   \n",
       "...         ...      ...     ...     ...  ...                   ...     ...   \n",
       "524.0  2.770917  2.77100   3.231   3.279  ...              1.916917  1.9150   \n",
       "525.0  2.785500  2.78300   3.001   3.244  ...              1.896333  1.8925   \n",
       "526.0  2.815583  2.81700   2.885   3.057  ...              1.921667  1.9275   \n",
       "527.0  2.758364  2.74500   2.787   2.886  ...              1.947727  1.9450   \n",
       "528.0  2.735667  2.73600   2.818   2.880  ...              1.930917  1.9230   \n",
       "\n",
       "      FP Transmission %                             FP Temp. Sample deg. C  \\\n",
       "                    min     max       mean   median                    min   \n",
       "CL_ID                                                                        \n",
       "202.0            94.855  98.785  97.617167  98.7050                 18.750   \n",
       "203.0            95.335  95.635  95.506909  95.5100                 18.770   \n",
       "204.0            93.155  96.070  94.756000  95.7500                 18.590   \n",
       "205.0            93.475  96.210  95.098958  96.1050                 18.600   \n",
       "206.0            94.140  96.145  95.072818  95.0250                 18.630   \n",
       "...                 ...     ...        ...      ...                    ...   \n",
       "524.0            76.340  76.660  76.555000  76.5850                 19.235   \n",
       "525.0            76.605  76.725  76.699583  76.7250                 19.150   \n",
       "526.0            75.975  76.570  76.360083  76.4100                 19.065   \n",
       "527.0            75.290  75.765  75.410909  75.2900                 19.000   \n",
       "528.0            75.290  76.145  75.695417  75.6875                 18.950   \n",
       "\n",
       "                                   \n",
       "          max       mean   median  \n",
       "CL_ID                              \n",
       "202.0  19.960  19.590800  19.9400  \n",
       "203.0  18.790  18.779636  18.7800  \n",
       "204.0  18.800  18.711905  18.7900  \n",
       "205.0  18.800  18.714583  18.7900  \n",
       "206.0  18.790  18.718455  18.7275  \n",
       "...       ...        ...      ...  \n",
       "524.0  19.320  19.275417  19.2700  \n",
       "525.0  19.225  19.194167  19.2025  \n",
       "526.0  19.143  19.098333  19.0975  \n",
       "527.0  19.060  19.021818  19.0100  \n",
       "528.0  18.990  18.965417  18.9675  \n",
       "\n",
       "[237 rows x 128 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output filepath\n",
    "# Make this whatever you'd like, I'm just appending \"_stats\" to the original filename\n",
    "out_path = \"May_RMP_merged_20secMed (1)SpatialJoin_stats.csv\"\n",
    "\n",
    "# Flatten the hierarchical columns\n",
    "df_stats.columns = [' '.join(col).strip() for col in df_stats.columns.values]\n",
    "\n",
    "# Write the csv\n",
    "df_stats.to_csv(out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And thats a wrap!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
